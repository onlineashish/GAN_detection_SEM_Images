train.py  --name  2class  --dataroot  dataset  --classes  FastGan,StyleGAN_ADA  --batch_size  128  --delr_freq  10  --lr  0.0002  --niter  50
cwd: /home/ashish/NPR-DeepfakeDetectionResnet18
(Val @ epoch 0) acc: 0.5; ap: 0.6243106430769265
(Val @ epoch 1) acc: 0.5266666666666666; ap: 0.6260467578445985
(Val @ epoch 2) acc: 0.5; ap: 0.6429546206218725
(Val @ epoch 3) acc: 0.5; ap: 0.5201385101254842
(Val @ epoch 4) acc: 0.5; ap: 0.48275017844143153
(Val @ epoch 5) acc: 0.5; ap: 0.5153791666006914
(Val @ epoch 6) acc: 0.5; ap: 0.5614701223708928
(Val @ epoch 7) acc: 0.5; ap: 0.591799384602067
(Val @ epoch 8) acc: 0.5; ap: 0.9129932398171965
(Val @ epoch 9) acc: 0.5; ap: 0.9087737634636619
2024_03_24_18_43_32 changing lr at the end of epoch 10, iters 99
*************************
Changing lr from 0.0002 to 0.00018
*************************
(Val @ epoch 10) acc: 0.92; ap: 0.9942968819433925
(Val @ epoch 11) acc: 0.96; ap: 0.9867763751383279
(Val @ epoch 12) acc: 0.7466666666666667; ap: 0.9440672724820516
(Val @ epoch 13) acc: 0.9733333333333334; ap: 0.9969419718806883
(Val @ epoch 14) acc: 0.9466666666666667; ap: 0.9954293890139777
(Val @ epoch 15) acc: 0.9266666666666666; ap: 0.9955458230357723
(Val @ epoch 16) acc: 0.74; ap: 0.9935530608238
(Val @ epoch 17) acc: 0.58; ap: 0.9917439929152482
(Val @ epoch 18) acc: 0.82; ap: 0.9928670650906806
(Val @ epoch 19) acc: 0.9266666666666666; ap: 0.9966643257316209
2024_03_24_18_45_14 changing lr at the end of epoch 20, iters 189
*************************
Changing lr from 0.00018 to 0.000162
*************************
(Val @ epoch 20) acc: 0.86; ap: 0.9952848067443955
(Val @ epoch 21) acc: 0.96; ap: 0.9972330914183967
(Val @ epoch 22) acc: 0.8733333333333333; ap: 0.9980734145910615
(Val @ epoch 23) acc: 0.82; ap: 0.9968785596861259
(Val @ epoch 24) acc: 0.84; ap: 0.9985272635258569
(Val @ epoch 25) acc: 0.9466666666666667; ap: 0.9989561221140167
(Val @ epoch 26) acc: 0.9733333333333334; ap: 0.9987807467386414
(Val @ epoch 27) acc: 0.9933333333333333; ap: 0.9994871794871794
(Val @ epoch 28) acc: 0.9666666666666667; ap: 0.9974481587219202
(Val @ epoch 29) acc: 0.98; ap: 0.9998245614035086
2024_03_24_18_46_56 changing lr at the end of epoch 30, iters 279
*************************
Changing lr from 0.000162 to 0.00014580000000000002
*************************
(Val @ epoch 30) acc: 0.98; ap: 0.9994666034455506
(Val @ epoch 31) acc: 0.9733333333333334; ap: 0.9994759018759017
(Val @ epoch 32) acc: 0.9666666666666667; ap: 0.9985980983368148
(Val @ epoch 33) acc: 0.8666666666666667; ap: 0.9986048703856922
(Val @ epoch 34) acc: 0.9266666666666666; ap: 0.9999999999999999
(Val @ epoch 35) acc: 0.9666666666666667; ap: 0.9979177446884399
(Val @ epoch 36) acc: 0.98; ap: 0.9991292215292213
(Val @ epoch 37) acc: 0.72; ap: 0.9887703838459124
(Val @ epoch 38) acc: 0.8666666666666667; ap: 0.9944554355326538
(Val @ epoch 39) acc: 0.5; ap: 0.9787579665643416
2024_03_24_18_48_38 changing lr at the end of epoch 40, iters 369
*************************
Changing lr from 0.00014580000000000005 to 0.00013122000000000003
*************************
(Val @ epoch 40) acc: 0.9; ap: 0.9970383039911204
(Val @ epoch 41) acc: 0.8733333333333333; ap: 0.9964232142460374
(Val @ epoch 42) acc: 0.9533333333333334; ap: 0.9998245614035086
(Val @ epoch 43) acc: 0.64; ap: 0.9972098853960905
2024_03_24_18_49_14 Train loss: 0.01833472028374672 at step: 400 lr 0.00013122000000000003
(Val @ epoch 44) acc: 0.96; ap: 0.9998245614035086
(Val @ epoch 45) acc: 0.9066666666666666; ap: 0.9970062170473444
(Val @ epoch 46) acc: 0.9733333333333334; ap: 0.9999999999999998
(Val @ epoch 47) acc: 0.88; ap: 0.9999999999999998
(Val @ epoch 48) acc: 0.8; ap: 0.9977037552350138
(Val @ epoch 49) acc: 0.9466666666666667; ap: 0.9998245614035086
*************************
2024_03_24_18_50_11
(0 FastGan   ) acc: 96.6; ap: 99.9
(1 StyleGAN_ADA) acc: 94.7; ap: 100.0
(2 Mean      ) acc: 95.7; ap: 99.9
*************************
2024_03_24_18_50_13
Saving model ./checkpoints/2class2024_03_24_18_41_40/model_epoch_last.pth
